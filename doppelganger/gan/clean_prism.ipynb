{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599205888462",
   "display_name": "Python 3.7.1 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original prism tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../../synthetic-data-service/isaFull.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare a clean version of the prism csv\n",
    "\n",
    "Clean means \n",
    "\n",
    "-categorical data is one hot encoded  \n",
    "-NAs are dealt with  \n",
    "-dates are converted to dday (difference in dates between subsequent visits) \n",
    "\n",
    "Two options for dealing with first dday for each patient  \n",
    "\n",
    "-the first visit day for each patient is converted to 'first_dday' (first visit date - first ever visit date in whole dataset), and is treated as an attribute to capture \"global distribution\" (hence an extra column)  \n",
    "-the first visit day for each patient is calculated with (first visit date - first ever visit date in whole dataset), but not treated as an attribute (no extra column)  \n",
    "\n",
    "This CSV file can be used for evaluation between real and generated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define if first dday for each patient should be considered as an attribute or feature\n",
    "first_dday_as_attr = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select columns that are wanted\n",
    "data2 = data[['Participant_Id','Visit date [EUPATH_0000091]','Abdominal pain duration (days) [EUPATH_0000154]',\"Age at visit (years) [EUPATH_0000113]\", \"Anorexia duration (days) [EUPATH_0000155]\", \"Asexual Plasmodium parasite density, by microscopy [EUPATH_0000092]\", \"Cough duration (days) [EUPATH_0000156]\", \"Diarrhea duration (days) [EUPATH_0000157]\", \"Fatigue duration (days) [EUPATH_0000158]\", \"Fever, subjective duration (days) [EUPATH_0000164]\", \"Headache duration (days) [EUPATH_0000159]\", \"Height (cm) [EUPATH_0010075]\", \"Hemoglobin (g/dL) [EUPATH_0000047]\", \"Joint pains duration (days) [EUPATH_0000161]\", \"Muscle aches duration (days) [EUPATH_0000162]\", \"Temperature (C) [EUPATH_0000110]\", \"Vomiting duration (days) [EUPATH_0000165]\", \"Weight (kg) [EUPATH_0000732]\", 'Complicated malaria [EUPATH_0000040]', \"Febrile [EUPATH_0000097]\", \"ITN last night [EUPATH_0000216]\", \"Malaria diagnosis [EUPATH_0000090]\", \"Malaria diagnosis and parasite status [EUPATH_0000338]\", \"Malaria treatment [EUPATH_0000740]\", \"Plasmodium gametocytes present, by microscopy [EUPATH_0000207]\", \"Submicroscopic Plasmodium present, by LAMP [EUPATH_0000487]\", \"Visit type [EUPATH_0000311]\"]].copy().sort_values(by =['Participant_Id', 'Visit date [EUPATH_0000091]']).reset_index(drop=True)\n",
    "\n",
    "# rename columns\n",
    "data2.columns = ['id', 'date', 'ab_pain_dur', 'age', 'aneroxia_dur', 'plasmodium_density', 'cough_dur', 'diarrhea_dur', 'fatigue_dur', 'fever_dur', 'headache_dur', 'height', 'hemoglobin', 'joint_pain_dur', 'muscle_ache_dur', 'temp', 'vomit_dur', 'weight', 'complicated_malaria','febrile', 'ITN', 'malaria', 'malaria_parasite', 'malaria_treatment', 'plasmodium_gametocytes', 'plasmodium_lamp', 'visit_type']\n",
    "\n",
    "# drop a row which is mostly NAs\n",
    "data2 = data2.drop(44432)\n",
    "\n",
    "# fill NAs in duration columns and plasmodium density column with 0\n",
    "dur_cols = ['ab_pain_dur', 'aneroxia_dur', 'plasmodium_density', 'cough_dur', 'diarrhea_dur', 'fatigue_dur', 'fever_dur', 'headache_dur', 'joint_pain_dur', 'muscle_ache_dur', 'vomit_dur']\n",
    "for col in dur_cols:\n",
    "    data2[col] = data2[col].fillna(0)\n",
    "\n",
    "# fill NAs in numerical columns by interpolation\n",
    "num_cols = ['height', 'hemoglobin', 'temp', 'weight']\n",
    "for col in num_cols:\n",
    "    data2[col] = data2[col].interpolate(method='linear')\n",
    "\n",
    "# fill NAs in categorical columns with new category \"not applicable\"/\"no result\" etc\n",
    "data2['plasmodium_lamp'] = data2['plasmodium_lamp'].fillna('no_result')\n",
    "data2['ITN'] = data2['ITN'].fillna('not applicable')\n",
    "data2['complicated_malaria'] = data2['complicated_malaria'].fillna('not_assessed')\n",
    "data2['plasmodium_gametocytes'] = data2['plasmodium_gametocytes'].fillna('No')\n",
    "\n",
    "# replace white spaces with underscores so that it won't create trouble later\n",
    "data2 = data2.replace(' ', '_', regex=True)\n",
    "\n",
    "# convert categorical column values to lowercase\n",
    "# one hot encode categorical columns\n",
    "cat_cols = ['complicated_malaria', 'febrile', 'ITN', 'malaria', 'malaria_parasite', 'malaria_treatment', 'plasmodium_gametocytes', 'plasmodium_lamp', 'visit_type']\n",
    "for col in cat_cols:\n",
    "    data2[col] = data2[col].map(lambda x: x.lower() if isinstance(x,str) else x)\n",
    "    one_hot_cols = pd.get_dummies(data2[col], prefix=col)\n",
    "    data2 = pd.concat([data2, one_hot_cols], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if first_dday_as_attr:\n",
    "    # find delta day between visits\n",
    "    # for first visit, we fill in with 0 for now\n",
    "    data2['id_diff'] = data2['id'].diff()\n",
    "    data2['date'] = pd.to_datetime(data2['date'])\n",
    "    data2['dday'] = data2['date'].diff()\n",
    "    def fill_first_dday(row):\n",
    "        if row['id_diff'] != 0:\n",
    "            return (row['date']- row['date']) # to get 0 in datetime format\n",
    "        else:\n",
    "            return row['dday']\n",
    "    data2['dday'] = data2.apply(fill_first_dday, axis=1)\n",
    "    data2['dday'] = data2['dday'].dt.days.astype('int16') # get int value from datetime format\n",
    "\n",
    "    # get delta day for first visit\n",
    "    # this is a separate column from above as we will treat it as an attribute rather than feature\n",
    "    earliest_date = min(data2['date'])\n",
    "    def get_first_dday(row, earliest_date):\n",
    "        if row['id_diff'] != 0:\n",
    "            return (row['date']- earliest_date)\n",
    "    data2['first_dday'] = data2.apply(get_first_dday,args=(earliest_date,), axis=1)\n",
    "    data2['first_dday'] = data2['first_dday'].fillna(method='ffill')\n",
    "    data2['first_dday'] = data2['first_dday'].dt.days.astype('int16')\n",
    "\n",
    "    # only take patiente with more than 5 visits\n",
    "    data_5above = data2[(data2.groupby('id')['id'].transform('size') >= 5)].reset_index(drop=True)\n",
    "    data_5above = data_5above.sort_values(by=['id', 'date'])\n",
    "\n",
    "    # remove unwanted columns\n",
    "    data_5above = data_5above.drop(columns=['date','complicated_malaria', 'febrile', 'ITN', 'malaria', 'malaria_parasite', 'malaria_treatment', 'plasmodium_gametocytes', 'plasmodium_lamp', 'visit_type', 'id_diff'])\n",
    "\n",
    "    # write data into a csv\n",
    "    # data_5above.to_csv('data/ori_prism_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not first_dday_as_attr:\n",
    "    # find delta day between visits\n",
    "    # for first visit, we find first visit date of patient - first ever visit in dataset\n",
    "    data2['id_diff'] = data2['id'].diff()\n",
    "    data2['date'] = pd.to_datetime(data2['date'])\n",
    "    data2['dday'] = data2['date'].diff()\n",
    "\n",
    "    #first ever visit in dataset\n",
    "    earliest_date = min(data2['date'])\n",
    "\n",
    "    def get_first_dday(row, earliest_date):\n",
    "        if row['id_diff'] != 0:\n",
    "            return (row['date'] - earliest_date)\n",
    "        else:\n",
    "            return row['dday']\n",
    "    data2['dday'] = data2.apply(get_first_dday, args=(earliest_date,), axis=1)\n",
    "    data2['dday'] = data2['dday'].dt.days.astype('int16') # get int value from datetime format\n",
    "\n",
    "    # only take patiente with more than 5 visits\n",
    "    data_5above = data2[(data2.groupby('id')['id'].transform('size') >= 5)].reset_index(drop=True)\n",
    "    data_5above = data_5above.sort_values(by=['id', 'date'])\n",
    "\n",
    "    # remove unwanted columns\n",
    "    data_5above = data_5above.drop(columns=['date','complicated_malaria', 'febrile', 'ITN', 'malaria', 'malaria_parasite', 'malaria_treatment', 'plasmodium_gametocytes', 'plasmodium_lamp', 'visit_type', 'id_diff'])\n",
    "\n",
    "    # write data into a csv\n",
    "    # data_5above.to_csv('data_attr/ori_prism_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert CSV into a form that can be fed into the DoppelGANger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def real_data_loading(path):\n",
    "    \"\"\"\n",
    "    takes in cleaned dataset \n",
    "    and returns features, gen_flag, attributes\n",
    "    to be saved in data_train.npz, \n",
    "    min_ and max_ for renormalization,\n",
    "    feature_col and attribute_col to name output file columns\n",
    "    \"\"\"\n",
    "\n",
    "    data = pd.read_csv(path)\n",
    "    # fill in any NAs that have been missed out\n",
    "    data.interpolate(method = 'linear', inplace=True)\n",
    "\n",
    "    # normalizing data\n",
    "    min_val = data.min()\n",
    "    max_val = data.max()\n",
    "    data = (data - min_val) / (max_val - min_val + 1e-7)\n",
    "    id_unique = data.id.unique()\n",
    "\n",
    "    # CHANGE feature cols according to dataset\n",
    "    feature_cols = ['ab_pain_dur', 'age', 'aneroxia_dur', 'plasmodium_density', 'cough_dur', 'diarrhea_dur', \n",
    "        'fatigue_dur', 'fever_dur', 'headache_dur', 'height', 'hemoglobin', 'joint_pain_dur', 'muscle_ache_dur', \n",
    "        'temp', 'vomit_dur', 'weight', 'complicated_malaria_no', 'complicated_malaria_not_assessed', \n",
    "        'complicated_malaria_yes', 'febrile_no', 'febrile_yes', 'ITN_no', 'ITN_not_applicable', 'ITN_yes',\n",
    "        'malaria_no', 'malaria_yes',\n",
    "        'malaria_parasite_blood_smear_indicated_but_not_done',\n",
    "        'malaria_parasite_blood_smear_negative_/_lamp_negative',\n",
    "        'malaria_parasite_blood_smear_negative_/_lamp_not_done',\n",
    "        'malaria_parasite_blood_smear_negative_/_lamp_positive',\n",
    "        'malaria_parasite_blood_smear_not_indicated',\n",
    "        'malaria_parasite_blood_smear_positive_/_no_malaria',\n",
    "        'malaria_parasite_symptomatic_malaria',\n",
    "        'malaria_treatment_artmether-lumefantrine_for_uncomplicated_malaria',\n",
    "        'malaria_treatment_no_malaria_medications_given',\n",
    "        'malaria_treatment_quinine_for_uncomplicated_malaria_in_the_1st_trimester_of_pregnancy',\n",
    "        'malaria_treatment_quinine_for_uncomplicated_malaria_within_14_days_of_a_previous_treatment_for_malaria',\n",
    "        'malaria_treatment_quinine_or_artesunate_for_complicated_malaria',\n",
    "        'plasmodium_gametocytes_no', 'plasmodium_gametocytes_yes',\n",
    "        'plasmodium_lamp_negative', 'plasmodium_lamp_no_result',\n",
    "        'plasmodium_lamp_positive', 'visit_type_enrollment',\n",
    "        'visit_type_scheduled_visit', 'visit_type_unscheduled_visit', 'dday']\n",
    "\n",
    "    # CHANGE attribute columns according to dataset\n",
    "    attribute_cols = ['first_dday']\n",
    "\n",
    "    features =[] \n",
    "    attributes = []\n",
    "    gen_flag = []\n",
    "\n",
    "    # iterate over each id\n",
    "    for i in id_unique:\n",
    "        #get features for each participant\n",
    "        child = np.array(data.loc[data['id'] == i][feature_cols])\n",
    "\n",
    "        if len(child) >= 5:\n",
    "            # get padded gen_flag according to length of time series for each child\n",
    "            gen_flag.append(np.concatenate([np.ones(len(child)), np.zeros(130-len(child))]))   \n",
    "            # get padded features for each child\n",
    "            child = np.pad(child, ((0, 130-len(child)), (0,0)))\n",
    "            features.append(child)\n",
    "            # get attributes for each child\n",
    "            # CHANGE attr col according to dataset\n",
    "            attributes.append(np.array(data.loc[data['id'] == i].iloc[0, -1])) #-1 for first_dday\n",
    "            # attributes.append(np.squeeze(np.array(data.loc[data['id'] == i][attribute_cols])[0]))\n",
    "\n",
    "    min_val = min_val.drop('id')\n",
    "    max_val = max_val.drop('id')\n",
    "  \n",
    "    return np.array(features), np.array(attributes), np.array(gen_flag), min_val, max_val, feature_cols, attribute_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_feature, data_attribute, data_gen_flag, min_, max_, feature_cols, attribute_cols = real_data_loading('data/ori_prism_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example of saving data in the format that can be processed by the doppelganger\n",
    "\n",
    "An example of the `npz` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1347, 130, 47)\n(1347, 1)\n(1347, 130)\n"
    }
   ],
   "source": [
    "if first_dday_as_attr: \n",
    "    data_feature, data_attribute, data_gen_flag, min_, max_, feature_cols, attribute_cols = real_data_loading('data_attr/ori_prism_cleaned.csv')\n",
    "    # first dday as attr\n",
    "    data_attribute = data_attribute.reshape((-1, 1))\n",
    "\n",
    "    print(data_feature.shape)\n",
    "    print(data_attribute.shape)\n",
    "    print(data_gen_flag.shape)\n",
    "    #np.savez('data_attr/data_train.npz', data_feature=data_feature, data_attribute=data_attribute, data_gen_flag=data_gen_flag)\n",
    "else:\n",
    "    data_feature, _, data_gen_flag, min_, max_, feature_cols, attribute_cols = real_data_loading('data/ori_prism_cleaned.csv')\n",
    "    # temporarily use all ones for attributes\n",
    "    data_attribute = np.ones((1347, 1))\n",
    "\n",
    "    print(data_feature.shape)\n",
    "    print(data_attribute.shape)\n",
    "    print(data_gen_flag.shape)\n",
    "    #np.savez('data/data_train.npz', data_feature=data_feature, data_attribute=data_attribute, data_gen_flag=data_gen_flag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example for the `pkl` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:  \n",
    "\n",
    "The first line `Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False)` corresponds to `ab_pain_dur` which is continuous, has only one dimension, is noramlized between 0 and 1.  \n",
    " \n",
    "The 2nd last line `Output(type_=OutputType.DISCRETE, dim=3, normalization=None, is_gen_flag=False)` corresponds to `visit_type` which is categorical (discrete), contains 3 categories (enrollment, scheduled, unscheduled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from output import *\n",
    "data_feature_output = [\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.DISCRETE, dim=3, normalization=None, is_gen_flag=False),\n",
    "    Output(type_=OutputType.DISCRETE, dim=2, normalization=None, is_gen_flag=False),\n",
    "    Output(type_=OutputType.DISCRETE, dim=3, normalization=None, is_gen_flag=False),\n",
    "    Output(type_=OutputType.DISCRETE, dim=2, normalization=None, is_gen_flag=False),\n",
    "    Output(type_=OutputType.DISCRETE, dim=7, normalization=None, is_gen_flag=False),\n",
    "    Output(type_=OutputType.DISCRETE, dim=5, normalization=None, is_gen_flag=False),\n",
    "    Output(type_=OutputType.DISCRETE, dim=2, normalization=None, is_gen_flag=False),\n",
    "    Output(type_=OutputType.DISCRETE, dim=3, normalization=None, is_gen_flag=False),\n",
    "    Output(type_=OutputType.DISCRETE, dim=3, normalization=None, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False)]\n",
    "\n",
    "# with open('data/data_feature_output.pkl', 'wb') as f:\n",
    "#     pickle.dump(data_feature_output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_attribute_output = [Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False)]\n",
    "\n",
    "# with open('data/data_attribute_output.pkl', 'wb') as f:\n",
    "#     pickle.dump(data_attribute_output, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converts `npz` file generated by the DoppelGANger to an intermediate CSV format\n",
    "\n",
    "The CSV contains one hot encoding, unrounded values and dday which can be used for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently works only for one feature, where first dday is the feature\n",
    "def gen_feature_loading(path, feature_cols, attribute_cols, min_val, max_val, seq_len=130):\n",
    "    \"\"\"\n",
    "    loads in generated npz file and returns a csv for generated data\n",
    "    Args:\n",
    "    path: path to npz file from doppelganger\n",
    "    feature_cols: column names for features in dataset\n",
    "    attribute_cols: column names for attributes in dataset\n",
    "    min_val: min val for each of the normalized columns for renormalisation\n",
    "    max_val: max val for each of the normalized columns for renormalisation\n",
    "    seq_len: max sequence length for each patient\n",
    "    \"\"\"\n",
    "\n",
    "    data = np.load(path)\n",
    "    \n",
    "    # get generate features (temporal data)\n",
    "    data_feat = np.clip(data['data_feature'], 0, 1)\n",
    "    dim = data['data_feature'].shape[2]\n",
    "    data_stack = data_feat.reshape((-1,dim))\n",
    "\n",
    "    # get generated attributes (static data)\n",
    "    data_attr = data['data_attribute']\n",
    "    data_attr = np.repeat(data_attr, seq_len)\n",
    "\n",
    "    # create a dataframe from the array\n",
    "    data_df = pd.DataFrame(data_stack)\n",
    "    data_df.columns = feature_cols\n",
    "    data_df['first_dday'] = data_attr # we only have one column for attribute\n",
    "    data_df['id'] = data_df.index // seq_len + 1\n",
    "\n",
    "    # remove padded columns\n",
    "    data_df = data_df.drop(data_df[(data_df.weight == 0) & (data_df.height == 0)].index)\n",
    "    \n",
    "    # renormalization\n",
    "    cols_to_renormalize = feature_cols + attribute_cols\n",
    "    data_df[cols_to_renormalize] = data_df[cols_to_renormalize] * (np.array(max_val) - np.array(min_val)) + np.array(min_val)\n",
    "\n",
    "    # write output to csv file\n",
    "    #data_df.to_csv('gen_prism.csv', index=False)\n",
    "\n",
    "    return data_df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert intermediate CSV to the format original data is in\n",
    "\n",
    "Converts the intermediate CSV above to a \"normal\" CSV format where one hot encoding has been reversed and the dday has been converted to calendar dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_to_ori_format(dataframe):\n",
    "  \n",
    "    \"\"\"\n",
    "    converts df that contains one hot encoding, unrounded values and dday values\n",
    "    back to the original format where the data is received, with categorical values \n",
    "    in the same column and date in which an event occured\n",
    "    \n",
    "    Args:\n",
    "    dataframe: dataframe with one-hot encoding, dday\n",
    "    \n",
    "    Returns:\n",
    "    df: dataframe with one-hot encoding reversed, dday converted to date\n",
    "    \"\"\"\n",
    "\n",
    "    df = dataframe.copy()\n",
    "\n",
    "    cat_cols = ['complicated_malaria', 'febrile', 'ITN', 'malaria_parasite', 'malaria_treatment', 'plasmodium_gametocytes', 'plasmodium_lamp', 'visit_type']\n",
    "    \n",
    "    # for each categorical data\n",
    "    for cat_col in cat_cols:\n",
    "        # get the one hot encoded columns for that category\n",
    "        related_cols = [col for col in df if col.startswith(cat_col)]\n",
    "        # \"reverse\" the one hot encoding\n",
    "        df[cat_col] = df[related_cols].idxmax(1).str.replace(cat_col+'_', '')\n",
    "        # remove extra columns\n",
    "        df = df.drop(columns=related_cols)\n",
    "\n",
    "    # malaria is not included in loop above bcoz columns that start with 'malaria_'\n",
    "    # includes columns that start with 'malaria_parasite', 'malaria_treatment'\n",
    "    # which messes things up\n",
    "    df['malaria'] = df[['malaria_yes', 'malaria_no']].idxmax(1).str.replace('malaria_', '')\n",
    "    df = df.drop(columns=['malaria_yes', 'malaria_no'])\n",
    "\n",
    "    # replace underscores with white spaces\n",
    "    # revert back to original format of data\n",
    "    df = df.replace('_', ' ', regex=True)\n",
    "\n",
    "    # round off data according to original decimal places\n",
    "    dur_cols = [col for col in df if col.endswith('_dur')]\n",
    "    df[dur_cols] = df[dur_cols].round()\n",
    "    df[['dday', 'first_dday']] = df[['dday', 'first_dday']].round()\n",
    "    df[['age', 'hemoglobin']] = df[['age', 'height']].round(2)\n",
    "    df[['height', 'temp', 'weight', 'plasmodium_density']] = df[['height', 'temp', 'weight','plasmodium_density']].round(1)\n",
    "\n",
    "    # convert dday back to date\n",
    "    # first_dday: first visit day for that patient (to capture global distribution)\n",
    "    # dday: diff in days between subsequent visit\n",
    "    earliest_date = pd.to_datetime('2011-07-29')\n",
    "    df['date'] = pd.to_timedelta(df['first_dday'], unit='D') + earliest_date\n",
    "    df['day_num'] = df.groupby('id')['dday'].cumsum()\n",
    "    df['date'] = df['date'] + pd.to_timedelta(df['day_num'], unit='D')\n",
    "\n",
    "    # select and reorder wanted columns\n",
    "    rearranged_cols = ['id', 'date', 'ab_pain_dur', 'age', 'aneroxia_dur', 'plasmodium_density', 'cough_dur', 'diarrhea_dur', \n",
    "            'fatigue_dur', 'fever_dur', 'headache_dur', 'height', 'hemoglobin', 'joint_pain_dur', 'muscle_ache_dur', \n",
    "            'temp', 'vomit_dur', 'weight'] + cat_cols + ['malaria']\n",
    "    df = df[rearranged_cols]\n",
    "\n",
    "    return df\n"
   ]
  }
 ]
}