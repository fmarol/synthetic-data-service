{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598967832049",
   "display_name": "Python 3.7.1 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../../synthetic-data-service/isaFull.tsv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare a clean version of the prism csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select columns that are wanted\n",
    "data2 = data[['Participant_Id','Visit date [EUPATH_0000091]','Abdominal pain duration (days) [EUPATH_0000154]',\"Age at visit (years) [EUPATH_0000113]\", \"Anorexia duration (days) [EUPATH_0000155]\", \"Asexual Plasmodium parasite density, by microscopy [EUPATH_0000092]\", \"Cough duration (days) [EUPATH_0000156]\", \"Diarrhea duration (days) [EUPATH_0000157]\", \"Fatigue duration (days) [EUPATH_0000158]\", \"Fever, subjective duration (days) [EUPATH_0000164]\", \"Headache duration (days) [EUPATH_0000159]\", \"Height (cm) [EUPATH_0010075]\", \"Hemoglobin (g/dL) [EUPATH_0000047]\", \"Joint pains duration (days) [EUPATH_0000161]\", \"Muscle aches duration (days) [EUPATH_0000162]\", \"Temperature (C) [EUPATH_0000110]\", \"Vomiting duration (days) [EUPATH_0000165]\", \"Weight (kg) [EUPATH_0000732]\", 'Complicated malaria [EUPATH_0000040]', \"Febrile [EUPATH_0000097]\", \"ITN last night [EUPATH_0000216]\", \"Malaria diagnosis [EUPATH_0000090]\", \"Malaria diagnosis and parasite status [EUPATH_0000338]\", \"Malaria treatment [EUPATH_0000740]\", \"Plasmodium gametocytes present, by microscopy [EUPATH_0000207]\", \"Submicroscopic Plasmodium present, by LAMP [EUPATH_0000487]\", \"Visit type [EUPATH_0000311]\"]].copy().sort_values(by =['Participant_Id', 'Visit date [EUPATH_0000091]']).reset_index(drop=True)\n",
    "\n",
    "# rename columns\n",
    "data2.columns = ['id', 'date', 'ab_pain_dur', 'age', 'aneroxia_dur', 'plasmodium_density', 'cough_dur', 'diarrhea_dur', 'fatigue_dur', 'fever_dur', 'headache_dur', 'height', 'hemoglobin', 'joint_pain_dur', 'muscle_ache_dur', 'temp', 'vomit_dur', 'weight', 'complicated_malaria','febrile', 'ITN', 'malaria', 'malaria_parasite', 'malaria_treatment', 'plasmodium_gametocytes', 'plasmodium_lamp', 'visit_type']\n",
    "\n",
    "# drop a row which is mostly NAs\n",
    "data2 = data2.drop(44432)\n",
    "\n",
    "# fill NAs in duration columns and plasmodium density column with 0\n",
    "dur_cols = ['ab_pain_dur', 'aneroxia_dur', 'plasmodium_density', 'cough_dur', 'diarrhea_dur', 'fatigue_dur', 'fever_dur', 'headache_dur', 'joint_pain_dur', 'muscle_ache_dur', 'vomit_dur']\n",
    "for col in dur_cols:\n",
    "    data2[col] = data2[col].fillna(0)\n",
    "\n",
    "# fill NAs in numerical columns by interpolation\n",
    "num_cols = ['height', 'hemoglobin', 'temp', 'weight']\n",
    "for col in num_cols:\n",
    "    data2[col] = data2[col].interpolate(method='linear')\n",
    "\n",
    "# fill NAs in categorical columns with new category \"not applicable\"/\"no result\" etc\n",
    "data2['plasmodium_lamp'] = data2['plasmodium_lamp'].fillna('no_result')\n",
    "data2['ITN'] = data2['ITN'].fillna('not applicable')\n",
    "data2['complicated_malaria'] = data2['complicated_malaria'].fillna('not_assessed')\n",
    "data2['plasmodium_gametocytes'] = data2['plasmodium_gametocytes'].fillna('No')\n",
    "\n",
    "# replace white spaces with underscores so that it won't create trouble later\n",
    "data2 = data2.replace(' ', '_', regex=True)\n",
    "\n",
    "# convert categorical column values to lowercase\n",
    "# one hot encode categorical columns\n",
    "cat_cols = ['complicated_malaria', 'febrile', 'ITN', 'malaria', 'malaria_parasite', 'malaria_treatment', 'plasmodium_gametocytes', 'plasmodium_lamp', 'visit_type']\n",
    "for col in cat_cols:\n",
    "    data2[col] = data2[col].map(lambda x: x.lower() if isinstance(x,str) else x)\n",
    "    one_hot_cols = pd.get_dummies(data2[col], prefix=col)\n",
    "    data2 = pd.concat([data2, one_hot_cols], axis=1)\n",
    "\n",
    "# find delta day between visits\n",
    "# for first visit, we fill in with 0 for now\n",
    "data2['id_diff'] = data2['id'].diff()\n",
    "data2['date'] = pd.to_datetime(data2['date'])\n",
    "data2['dday'] = data2['date'].diff()\n",
    "def fill_first_dday(row):\n",
    "    if row['id_diff'] != 0:\n",
    "        return (row['date']- row['date']) # to get 0 in datetime format\n",
    "    else:\n",
    "        return row['dday']\n",
    "data2['dday'] = data2.apply(fill_first_dday, axis=1)\n",
    "data2['dday'] = data2['dday'].dt.days.astype('int16') # get int value from datetime format\n",
    "\n",
    "# get delta day for first visit\n",
    "# this is a separate column from above as we will treat it as an attribute rather than feature\n",
    "earliest_date = min(data2['date'])\n",
    "def get_first_dday(row, earliest_date):\n",
    "    if row['id_diff'] != 0:\n",
    "        return (row['date']- earliest_date)\n",
    "data2['first_dday'] = data2.apply(get_first_dday,args=(earliest_date,), axis=1)\n",
    "data2['first_dday'] = data2['first_dday'].fillna(method='ffill')\n",
    "data2['first_dday'] = data2['first_dday'].dt.days.astype('int16')\n",
    "\n",
    "# only take patiente with more than 5 visits\n",
    "data_5above = data2[(data2.groupby('id')['id'].transform('size') >= 5)].reset_index(drop=True)\n",
    "data_5above = data_5above.sort_values(by=['id', 'date'])\n",
    "\n",
    "# remove unwanted columns\n",
    "data_5above = data_5above.drop(columns=['date','complicated_malaria', 'febrile', 'ITN', 'malaria', 'malaria_parasite', 'malaria_treatment', 'plasmodium_gametocytes', 'plasmodium_lamp', 'visit_type', 'id_diff'])\n",
    "\n",
    "# write data into a csv\n",
    "# data_5above.to_csv('gan/data/ori_prism_cleaned.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def real_data_loading():\n",
    "    \"\"\"\n",
    "    takes in cleaned dataset \n",
    "    and returns features, gen_flag, attributes\n",
    "    to be saved in data_train.npz, \n",
    "    min_ and max_ for renormalization\n",
    "    \"\"\"\n",
    "\n",
    "    data = pd.read_csv('data/ori_prism_cleaned.csv')\n",
    "    # fill in any NAs that have been missed out\n",
    "    data.interpolate(method = 'linear', inplace=True)\n",
    "\n",
    "    # normalizing data\n",
    "    min_val = data.min()\n",
    "    max_val = data.max()\n",
    "    data = (data - min_val) / (max_val - min_val + 1e-7)\n",
    "    id_unique = data.id.unique()\n",
    "\n",
    "    feature_cols = ['ab_pain_dur', 'age', 'aneroxia_dur', 'plasmodium_density', 'cough_dur', 'diarrhea_dur', \n",
    "        'fatigue_dur', 'fever_dur', 'headache_dur', 'height', 'hemoglobin', 'joint_pain_dur', 'muscle_ache_dur', \n",
    "        'temp', 'vomit_dur', 'weight', 'complicated_malaria_no', 'complicated_malaria_not_assessed', \n",
    "        'complicated_malaria_yes', 'febrile_no', 'febrile_yes', 'ITN_no', 'ITN_not_applicable', 'ITN_yes',\n",
    "        'malaria_no', 'malaria_yes',\n",
    "        'malaria_parasite_blood_smear_indicated_but_not_done',\n",
    "        'malaria_parasite_blood_smear_negative_/_lamp_negative',\n",
    "        'malaria_parasite_blood_smear_negative_/_lamp_not_done',\n",
    "        'malaria_parasite_blood_smear_negative_/_lamp_positive',\n",
    "        'malaria_parasite_blood_smear_not_indicated',\n",
    "        'malaria_parasite_blood_smear_positive_/_no_malaria',\n",
    "        'malaria_parasite_symptomatic_malaria',\n",
    "        'malaria_treatment_artmether-lumefantrine_for_uncomplicated_malaria',\n",
    "        'malaria_treatment_no_malaria_medications_given',\n",
    "        'malaria_treatment_quinine_for_uncomplicated_malaria_in_the_1st_trimester_of_pregnancy',\n",
    "        'malaria_treatment_quinine_for_uncomplicated_malaria_within_14_days_of_a_previous_treatment_for_malaria',\n",
    "        'malaria_treatment_quinine_or_artesunate_for_complicated_malaria',\n",
    "        'plasmodium_gametocytes_no', 'plasmodium_gametocytes_yes',\n",
    "        'plasmodium_lamp_negative', 'plasmodium_lamp_no_result',\n",
    "        'plasmodium_lamp_positive', 'visit_type_enrollment',\n",
    "        'visit_type_scheduled_visit', 'visit_type_unscheduled_visit', 'dday']\n",
    "\n",
    "    features =[] \n",
    "    attributes = []\n",
    "    gen_flag = []\n",
    "\n",
    "    # iterate over each id\n",
    "    for i in id_unique:\n",
    "        #get features for each participant\n",
    "        child = np.array(data.loc[data['id'] == i][feature_cols])\n",
    "\n",
    "        if len(child) >= 5:\n",
    "            # get padded gen_flag according to length of time series for each child\n",
    "            gen_flag.append(np.concatenate([np.ones(len(child)), np.zeros(130-len(child))]))   \n",
    "            # get padded features for each child\n",
    "            child = np.pad(child, ((0, 130-len(child)), (0,0)))\n",
    "            features.append(child)\n",
    "            # get attributes for each child\n",
    "            attributes.append(np.array(data.loc[data['id'] == i].iloc[0, -1])) #-1 for first_dday\n",
    "\n",
    "    min_val = min_val.drop('id')\n",
    "    max_val = max_val.drop('id')\n",
    "  \n",
    "    return np.array(features), np.array(attributes), np.array(gen_flag), min_val, max_val, feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP\n",
    "def gen_feature_loading(path, feature_cols, seq_len=130):\n",
    "    \"\"\"\n",
    "    loads in generated npz file and returns a csv for generated data\n",
    "    Args:\n",
    "    path: path to npz file from doppelganger\n",
    "    feature_cols: column names for features in dataset\n",
    "    seq_len: max sequence length for each patient\n",
    "    \"\"\"\n",
    "\n",
    "    data = np.load(path)\n",
    "    \n",
    "    data_out = np.clip(data['data_feature'], 0, 1)\n",
    "\n",
    "    dim = data['data_feature'].shape[2]\n",
    "    data_stack = data_out.reshape((-1,dim))\n",
    "\n",
    "    # create a dataframe from the array\n",
    "    data_df = pd.DataFrame(data_stack)\n",
    "    data_df['id'] = data_df.index // seq_len + 1\n",
    "    data_df.columns = feature_cols + ['id']\n",
    "\n",
    "    #remove padded columns\n",
    "    data_df = data_df.drop(data_df[(data_df.weight == 0) & (data_df.height == 0)].index)\n",
    "\n",
    "    #temporary \n",
    "    min_val = min_val.drop('first_dday')\n",
    "    max_val = max_val.drop('first_dday')\n",
    "\n",
    "    #renormalization\n",
    "    data_df[feature_cols] = data_df[feature_cols] * (np.array(max_val) - np.array(min_val)) + np.array(min_val)\n",
    "\n",
    "    #data_df.to_csv('gen_prism.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An example of saving data in the format that can be processed by the doppelganger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1347, 130, 47)\n(1347, 1)\n(1347, 130)\n"
    }
   ],
   "source": [
    "data_feature, data_attribute, data_gen_flag, min_, max_, feature_cols = real_data_loading()\n",
    "data_attribute = data_attribute.reshape((-1, 1))\n",
    "\n",
    "print(data_feature.shape)\n",
    "print(data_attribute.shape)\n",
    "print(data_gen_flag.shape)\n",
    "#np.savez('data/data_train.npz', data_feature=data_feature, data_attribute=data_attribute, data_gen_flag=data_gen_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from output import *\n",
    "data_feature_output = [\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False),\n",
    "    Output(type_=OutputType.DISCRETE, dim=3, normalization=None, is_gen_flag=False),\n",
    "    Output(type_=OutputType.DISCRETE, dim=2, normalization=None, is_gen_flag=False),\n",
    "    Output(type_=OutputType.DISCRETE, dim=3, normalization=None, is_gen_flag=False),\n",
    "    Output(type_=OutputType.DISCRETE, dim=2, normalization=None, is_gen_flag=False),\n",
    "    Output(type_=OutputType.DISCRETE, dim=7, normalization=None, is_gen_flag=False),\n",
    "    Output(type_=OutputType.DISCRETE, dim=5, normalization=None, is_gen_flag=False),\n",
    "    Output(type_=OutputType.DISCRETE, dim=2, normalization=None, is_gen_flag=False),\n",
    "    Output(type_=OutputType.DISCRETE, dim=3, normalization=None, is_gen_flag=False),\n",
    "    Output(type_=OutputType.DISCRETE, dim=3, normalization=None, is_gen_flag=False),\n",
    "    Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False)]\n",
    "\n",
    "# with open('data/data_feature_output.pkl', 'wb') as f:\n",
    "#     pickle.dump(data_feature_output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_attribute_output = [Output(type_=OutputType.CONTINUOUS, dim=1, normalization=Normalization.ZERO_ONE, is_gen_flag=False)]\n",
    "\n",
    "# with open('data/data_attribute_output.pkl', 'wb') as f:\n",
    "#     pickle.dump(data_attribute_output, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}